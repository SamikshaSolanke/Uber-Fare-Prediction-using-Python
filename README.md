# Uber-Fare-Prediction-using-Python

## ğŸ“Œ Project Overview
Uber Fare Prediction is a **machine learning project** that aims to accurately predict the fare amount of Uber rides based on various factors such as pickup and dropoff locations, distance, time of the day, and passenger count. This project implements multiple regression models, including **Linear Regression, Random Forest, Gradient Boosting, XGBoost, LightGBM, and Neural Networks**, to compare performance and optimize accuracy.

## ğŸš€ Features
âœ… Data Cleaning & Preprocessing  
âœ… Exploratory Data Analysis (EDA)  
âœ… Feature Engineering (Distance Calculation, Time Features)  
âœ… Model Training (Linear Regression, Random Forest, XGBoost, LightGBM, Neural Networks)  
âœ… Performance Evaluation (RMSE, RÂ² Score)  
âœ… Hyperparameter Tuning for Optimization  
âœ… Deployment-ready Code (Flask API integration - Optional)  

## ğŸ“‚ Dataset Information
The dataset contains **200,000** Uber ride records with the following features:
- **fare_amount** (Target variable)
- **pickup_datetime** (Date & time of ride)
- **pickup_latitude & pickup_longitude** (Pickup coordinates)
- **dropoff_latitude & dropoff_longitude** (Dropoff coordinates)
- **passenger_count** (Number of passengers)

## ğŸ”¬ Exploratory Data Analysis (EDA)
- Checked for **missing values** and handled them appropriately.
- Calculated **trip distance** using Haversine formula.
- Extracted **date-time features** (hour, day, month, weekday) from `pickup_datetime`.
- Visualized **fare distribution** and correlations using Seaborn & Matplotlib.

## ğŸ› ï¸ Model Training & Performance
### **1ï¸âƒ£ Baseline Model: Linear Regression**
- **RMSE**: `10.191632`  
- **RÂ² Score**: `0.001486` (Poor Performance)

### **2ï¸âƒ£ Best Performing Model: Random Forest**
- **RMSE**: `6.112316`  
- **RÂ² Score**: `0.640848`  

### **3ï¸âƒ£ Advanced Models: XGBoost & LightGBM**
- **XGBoost RMSE**: `6.748792` 
- **LightGBM RMSE**: `5.791985` 

## ğŸ† Key Takeaways
âœ” **Random Forest & Boosting models outperform Linear Regression.**  
âœ” **Hyperparameter tuning improves accuracy significantly.**  
âœ” **Deep Learning models (ANN) can further enhance predictions.**  
âœ” **LightGBM is the best choice for fast & scalable predictions.**  

## ğŸ› ï¸ Technologies Used
- **Programming Language**: Python ğŸ
- **Data Processing**: Pandas, NumPy
- **Visualization**: Matplotlib, Seaborn
- **Machine Learning Models**: Scikit-Learn, XGBoost, LightGBM, TensorFlow/Keras
- **Deployment (Optional)**: Flask/FastAPI

